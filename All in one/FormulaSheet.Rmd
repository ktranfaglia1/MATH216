---
title: "All in one R functions"
author: "Kyle Tranfaglia"
date: "2023-10-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE,message=FALSE)

library(dplyr)
library(ggplot2)
library(ggpubr)
library(flextable)
library(tidyr)
library(knitr)
library(tidyverse)
library(extraDistr)
library(nortest)
library(car)
library(BSDA)
```

# Importing Data file

```{r}
data0 <- read.csv("US_STATES.csv")
```

# Data Analytics

```{r}
VectorTest <- 1:10

VectorTest

data0[1,] # Display first row
data0[,2] # Display second column
data0[1:5,2:5] # Display first 5 rows and columns 2-5
data0[data0$Name=="Maryland",] # Find the information about Maryland
subset(data0, Name=="Maryland") # Find the information about Maryland
data0$Name # Find the information about all the names of the states
data0[data0$Region=="South",]$Name # Only display the names for all the states in the region “South”
subset(data0, Region=="South")$Name
select(data0[data0$Region=="South",],Name,Area,Population) # Only display the names, Area, and Population for all the states in the region “South”
select(data0[data0$Region=="South" & data0$Population>3000,],Name,Area,Population) # Only display the names, Areas, and Population for all the states in the region “South” AND have populations >3000
NEstates <- select(data0[data0$Region=="Northeast" & data0$Population>5000,],Name,Area,Population)
kable(NEstates) # Only display the names, Areas, and Population for all the states in the region “Northeast” AND have populations >5000 and display that object using kable function

DesStat <- function(datacol, title){ # Function for descriptive statistic table
  datasummary <- as.data.frame(list(N=length(datacol),min=min(datacol),firstQ=quantile(datacol,0.25),median=median(datacol),thirdQ=quantile(datacol,0.75),max=max(datacol),mean=round(mean(datacol),3),StDev=round(sd(datacol),3),Var=round(var(datacol),3)))
  
  
  datasummary<-flextable(datasummary) 
  datasummary<-set_caption(datasummary, title)
  
  save_as_docx(datasummary, path=paste(title,".docx"))
  datasummary
}
DesStat(data0$LifeExp, "Descriptive Statistics - life expectancy - Kyle Tranfaglia") # Function call

# Code for Frequency Table
FrequencyTable <- data0 %>% group_by(data0$Region, data0$HS_Grad) %>%
  summarise(Count=n())
FrequencyTable <- flextable(FrequencyTable)
FrequencyTable <- set_caption(FrequencyTable, "Frequency Table of Height/Sex - Kyle Tranfaglia")
FrequencyTable

# Function for comparative histogram
HistWithGroups <- function(data,xcol,xname,group,gname,bwidth){
  ggplot(data, aes(x=xcol,fill=group))+
    geom_histogram(aes(y=..density..),color="black",binwidth=bwidth,alpha=0.6, position="identity")+
    scale_y_continuous(labels=scales::percent_format())+
    xlab(xname)+
    scale_fill_discrete(name=gname)
  
}
data1 <- read.csv("Pulse.csv") # Open file to read data ... store in data2
HistWithGroups(data1,data1$Height,"Height",data1$Sex,"Sex",1) # Function call

ggplot(data1, aes(x=data1$Height))+
  geom_histogram(binwidth=1,color="black", fill="lightblue") # Simple ggplot template

# Pre-plotting and getting tally table
data1$Sex[data1$Sex==1]<-'Male'
data1$Sex[data1$Sex==2]<-'Female'

data1$Activity[data1$Activity==1]<-'Slight'
data1$Activity[data1$Activity==2]<-'Moderate'
data1$Activity[data1$Activity==3]<-'A lot'

SexCount <- data1 %>% group_by(Sex) %>%
  summarise(Count=n())


flextable(SexCount)

SexProportion <- round(SexCount$Count/sum(SexCount$Count),2)

SexStat <- cbind(SexCount,SexProportion)

flextable(SexStat)

## ggplot pie chart
ggplot(SexStat,aes(x="",y=SexProportion,fill=Sex))+
  geom_bar(stat="identity")+
  coord_polar("y",start=0)+
  theme_void()+
  geom_text(aes(label=paste("Count=",Count,"  Prop=", scales::percent(SexProportion))),position=position_stack(vjust=0.5))+
  scale_fill_manual(values=c("lightblue","orange"))

# Cross-tab
data1$Smokes[data1$Smokes==1]<-'Yes'
data1$Smokes[data1$Smokes==2]<-'No'

CrossCount3 <- data1 %>% group_by(Sex, Smokes) %>%
  tally()

CrossCount4 <- data1 %>% group_by(Sex, Smokes) %>%
  tally() %>%
  spread(Sex,n)

CrossCount4
```

# Check Normality

```{r}
hist(data0$LifeExp)
```

```{r}
library(car)

qqPlot(data0$LifeExp)
```

# Compute Mean, Variance, Standard Deviation, Quantile from Data Set

```{r}

lfexp <- data0$LifeExp

mean(lfexp)

var(lfexp)

sd(lfexp)

summary(lfexp)

length(lfexp)

min(lfexp)

max(lfexp)

median(lfexp)

quantile(lfexp)

quantile(lfexp, 0.25)

quantile(lfexp, 0.75)
```

in R,

p is usually for area under the curve and to the left of the cutting point - P[x\<=q]

q is the cutting point that p of the data will be to the left of that point

d is for discrete

binom for Binomial

pois for Poisson

norm for normal

# Binomial Random Variable

Assume the following random variable follows a binomial distribution with n=20, p=0.6

```{r}
# Function to plot Binomial random variables
Binom_plotter<-function(n,p,lb,ub){
x<-seq(0,n)
hx<-dbinom(x,n,p)


i<-x>= lb & x<= ub

hxi<-dbinom(x[i],n,p)


plot(x,hx,type='h', xlim=c(0,n),ylim=c(0,max(hx)))



if (lb>=0&lb<=n){
  abline(v=lb,lty=3,col='blue')
}

if (ub>=0&ub<=n){
  abline(v=ub,lty=3,col='blue')
}
par(new=T)
plot(x[i],hxi,type='h', col="red", xlim=c(0,n),ylim=c(0,max(hx)),xlab="",ylab="" )

par(new=F)


area <- pbinom(ub, n, p) - pbinom(lb, n, p) + dbinom(lb,n,p)
result <- paste("P(",lb,"\u2264 X \u2264",ub,") =",
   signif(area, digits=3), "\n",
   "n=", n, " p=", p)
mtext(result,3)

}
```

Example 1: Find P[x\<=13]

```{r}

pbinom(q=13, size=20, prob=0.6)

Binom_plotter(20,0.6,0,13)
```

Example 2: Find P[x\<13]

```{r}

pbinom(q=12, size=20, prob=0.6)
```

Example 3: Find P[x=13]

```{r}

dbinom(x=13, size=20, prob=0.6)
Binom_plotter(20,0.6,13,13)
```

Example 4: Find P[4\<x\<=13]

```{r}

pbinom(q=13, size=20, prob=0.6) - pbinom(q=4, size=20, prob=0.6)
Binom_plotter(20,0.6,5,13)
```

Example 5: Find P[4\<=x\<13]

```{r}

pbinom(q=12, size=20, prob=0.6) - pbinom(q=3, size=20, prob=0.6)
```

Example 6: Find P[4\<=x\<=13]

```{r}

pbinom(q=13, size=20, prob=0.6) - pbinom(q=3, size=20, prob=0.6)
```

Example 7: Find P[4\<x\<13]

```{r}

pbinom(q=12, size=20, prob=0.6) - pbinom(q=4, size=20, prob=0.6)
```

Example 8: Find P[x\>=13]

```{r}

pbinom(q=20, size=20, prob=0.6) - pbinom(q=12, size=20, prob=0.6)
```

Example 9: Find P[x\>13]

```{r}

pbinom(q=20, size=20, prob=0.6) - pbinom(q=13, size=20, prob=0.6)
Binom_plotter(20,0.6,14,20)
```

# Poisson Random Variable

rpois(n,lambda)-Which generates a random sample from the Poisson distribution

dpois(x,lambda)-generates $P(X=x)$ for the Poisson distribution

ppois(q,lambda)- calculates $P(X\leq x)$ for a Poisson distribution

qpois(p,lambda)- This gives the x value such that $P(X \leq x)=p$ for a Poisson distribution

suppose $\lambda=2.2$ Find $P(X>3)$ and $P(2.2< X < 5.1)$

```{r}

1 - ppois(3, 2.2)

ppois(5.1, 2.2) - ppois(2.2,2.2)
```

# Normal Random Variable

Given p, find q

Given q, find p

Different P[....]

Given that q, the cutting is 20 with a mean of 27 and a sd of 3, find p, as in find $P(X < 20)$

```{r}

pnorm(q = 20, mean = 27, sd = 3)
```

Given that p, the area under the curve is 0.90, being the 90th percentile, and there is a mean of 550 and sd of 100, find q, as in the corresponding cutting point x, for p(x) = 0.90

```{r}

qnorm(p = .90, mean = 550, sd = 100)
```

Find z0 such that 95% of the standard normal z values lie between -z0 and z0. So, find z0 such that $P(-z0 <= z <= z0) = 0.95$

```{r}

qnorm(p = 0.975, mean = 0, sd = 1)
```

# Uniform Distribution

```{r}
# define the x-axis
x_uniform<-seq(1,30, length=30)

# calculate the uniform probabilities
y_uniform<- ddunif(x_uniform,min=1,max=30)

# plot the distribution
plot(x_uniform,y_uniform, type='h')


```

To calculate a probability of $P(5< X \leq 7)$ we would o the following:

```{r}

round(pdunif(7,1,30)-pdunif(5,1,30),5) 
```

However, in the case of $P(5\leq X\leq 7)$, we should do some adjustments.

```{r}

round(pdunif(7,1,30)-pdunif(4,1,30),5)
```

Now calculate $P(10 < X \leq 18.1)$ and $P(10 \leq X \leq 18.1)$

```{r}

round(pdunif(18.1,1,30)-pdunif(10,1,30),10) 
round(pdunif(18.1,1,30)-pdunif(9,1,30),10) 
```

To get a list of random data in R we can do the following:

```{r}

unifrom_sample<-rdunif(100,1,30) 
```

We can then plot the histogram using the hist function:

```{r}
# basic plot 
hist(unifrom_sample) 
# correct the bining 
hist(unifrom_sample, breaks=c(1,6,11,16,21,26,30),xlim=c(1,30))
```

We can also overlay the distribution over the histogram:

```{r}

a<-1
b<-30
x_uniform<-seq(a,b, length=b)

y_uniform<- dunif(x_uniform,min=a,max=b)

hist(unifrom_sample, breaks=c(1,6,11,16,21,26,30),xlim=c(1,30))

for (i in 1:30){
  segments(i,0,i,1/(b-a), lwd=2)
}   
```

# Confidence Interval

```{r}

CI_data <- function(data, PopSDknown, PopSDvalue, ConfCoef, digit ){
  
  # data should be a column of numeric data
  # PopSDknown should be "Yes" or "No", whether the Population standard deviation is known or not.
  # PopSDvalue should be the value of the pop sd value. If pop sd is NOT known, just input 0.
  # ConfCoef is the confidence coefficient, should be a real number between 0 and 1.
  # digit is the number of digits you want to present in the CI
  
  x_bar <- mean(data)
  n <- length(data)
  
  confLv <- ConfCoef*100
  
  if (PopSDknown == "Yes"){
        crval <- qnorm((1+ConfCoef)/2)
        SD <- PopSDvalue
        output1 <- paste("The population standard deviation is", bquote(.(PopSDvalue)))
        
  }
  else if (PopSDknown == "No"){
        crval = qt((1+ConfCoef)/2,n-1)
        SD <- sd(data)
        output1 <- paste("The population standard deviation is unknown.")
  }
  
  ci_ub <- round(x_bar + crval*SD/sqrt(n),digit)
  ci_lb <- round(x_bar - crval*SD/sqrt(n),digit)
  

  
  
  cat(output1,"\nThe sample size is", bquote(.(n)), ". The sample mean is", bquote(.(x_bar)), ". The sample standard deviation is", bquote(.(sd(data))),"\nThe", bquote(.(confLv)), "% Confidence Interval for the population mean is (", bquote(.(ci_lb)), bquote(.(ci_ub)), ").\n" )
  
}

CI_stat <- function(x_bar,n, PopSDknown, SD, ConfCoef, digit ){
  
  # x_bar is the sample mean
  # n is the sample size
  # PopSDknown should be "Yes" or "No", whether the Population standard deviation is known or not
  # SD is the pop sd or sample sd, depends on the input of PopSDknown
  # ConfCoef is the confidence coefficient, should be a real number between 0 and 1.
  # digit is the number of digits you want to present in the CI
  

  confLv <- ConfCoef*100
  
  if (PopSDknown == "Yes"){
        crval <- qnorm((1+ConfCoef)/2)
        output1 <- paste("The population standard deviation is", bquote(.(SD)))
        
  }
  else if (PopSDknown == "No"){
        crval = qt((1+ConfCoef)/2,n-1)
        output1 <- paste("The population standard deviation is unknown.")
  }
  
  ci_ub <- round(x_bar + crval*SD/sqrt(n),digit)
  ci_lb <- round(x_bar - crval*SD/sqrt(n),digit)

  
  cat(output1,"\nThe sample size is", bquote(.(n)), ". The sample mean is", bquote(.(x_bar)), ". The sample standard deviation is", bquote(.(SD)),"\nThe", bquote(.(confLv)), "% Confidence Interval for the population mean is (", bquote(.(ci_lb)), bquote(.(ci_ub)), ").\n" )
  
}
```

```{r}
x <- rnorm(100,5,3)
CI_data(x,"No",0,0.95,4)
CI_data(x,"Yes",3,0.95,4)

CI_stat(4.711773,100,"Yes",3,0.95,4)

# Insert Image Syntax: ![text about the image](image file name)
```

# Table Ploting

```{r}

Sample_Size <- c(10,40,90, 160, 250)
confidence_Proportion <- c(.94, .97,.96, .97, .94)
avg_Width <- c(1.33524,.63044,.41996,.31374,.24858)
CI_table_90_normal <- data.frame(Sample_Size , confidence_Proportion, avg_Width)

colnames(CI_table_90_normal)<-c("Sample Size", "Prop of CIs Covering True Mean", "Ave Width of CIs")

library(knitr)
kable(CI_table_90_normal,padding=6,align="ccc",caption="95% CIs from Normal Pop - Different Sample Sizes")


Parent_distribution <- c("Normal","Uniform","Right Skew", "Left Skew", "Bimodal", "Cauchy")
propofCI <- c(.88, .78, .78, .87, .79, .65)
numonLeft <- c(9, 9, 14, 6, 7, 30)
numonRight <- c(3, 13, 8, 7, 14, 5)
CI_table2 <- data.frame(Parent_distribution , propofCI, numonLeft, numonRight)

colnames(CI_table2)<-c("Parent Distribution", "Prop of CIs Covering True Mean", "Num of left CI not cover true mean", "Num of right CI not cover true mean")

library(knitr)
kable(CI_table2,padding=6,align="ccc",caption="80% CIs from Different Pop - Sample Size 500")
```

# Hypothesis Testing

```{r}

mydata<-read.csv("firstgrade.csv")

x<-mydata["Height"]

y<-mydata["Weight"]

# Since we are directly given data, we should use 1-sample t test (R code is t.test())

# x = data, mu = mu0 in the hypothesis
# Alternative is either "two.sided", "greater", or "less" ... "two.sided" if HA: mu != mu0
# conf.level = l - alpha

t.test(x=x, mu=42, alternative = "greater", conf.level = 1-0.05)

# To test a data set to determine whether or not it is reasonable to assume it is a random sample from a normal distribution we will use the Anderson-Darling Test
# Anderson-Darling Test

x_Z25<-rnorm(25,0,1)

ad.test(x_Z25)

qqPlot(x_Z25)

# t-test with summary statistics

tsum.test(mean.x=6.45,s.x=4,n.x=45,mu=6,alternative = 'greater',conf.level = .95)

# If sigma is known, and either you have large n, or small n but normal population, you can use z-test

# z.test(x=data, sigma.x=sigma, mu=mu0, alternative = "xxx", conf.level = 0.xx)

# zsum.test(mean.x=xbar, s.x=sigma, n.x=n, mu=mu0, alternative = "xxx", conf.level = 0.xx)

# Wilcoxon test
# wilcox.test(x=data, mu=mu0, alternative = "xxx", conf.level = 0.xx)

# Sign Test
# SIGN.test(x=data, md=md0, alternative = "xxx", conf.level = 0.xx)

```

# Quiz 2 Workspace

```{r}

Binom_plotter(3,0.2,0,4)
Binom_plotter(3,0.2,0,2)
pbinom(q=2, size=3, prob=0.2)

pnorm(q = 15, mean = 11, sd = 4) - pnorm(q = 10, mean = 11, sd = 4)
1 - pnorm(q = 20, mean = 11, sd = 4)
qnorm(p=0.90, mean = 11, sd = 4)
```

# Test 2 Practice Exam Workspace

```{r}
# Question 3 Practice Exam .. Gets probability distribution of x
x <- c(0, 1, 2, 3, 4)

dbinom(x, 4, 0.2)

pbinom(q=2, size=4, prob=0.2)

data2 <- read.csv("Exam2Prac7.csv")
hist(data2$Sample.Data)

normal_data <- rnorm(1000, mean = 0, sd = 1)
hist(normal_data)

mean(normal_data)
sd(normal_data)

mn <- mean(data2$SampleData)
SD <- sd(data2$SampleData)

mn
SD

# Exponential Distribution
# known cutting point q, to find area P[x<=q]
pexp(5, 1/6.25)
# Known area p[x<=q] to find cutting point q
qexp(0.275, 1/6.25)

1 - pnorm(82, 80, 1)

1 - pnorm(0.30, 0.27, 0.0444)
```

# Exam 2 Workspace

```{r}

data3 <- read.csv("Exam2.csv")
hist(data3$SampleData)

normal_data <- rnorm(1000, mean = 0, sd = 1)
hist(normal_data)

mean(normal_data)
sd(normal_data)

DataMean <- mean(data3$SampleData)
DataSD <- sd(data3$SampleData)

DataMean
DataSD

# Interval Bounds (92% Confidence)
qnorm(.96, DataMean, DataSD) 
qnorm(.04, DataMean, DataSD)

pnorm(q = 69, mean = 75, sd = 8) - pnorm(q = 60, mean = 75, sd = 8)

1 - pnorm(q = 90, mean = 75, sd = 8)

qnorm(.90, 75, 8)


x1 <- c(0, 1, 2, 3, 4, 5)

dbinom(x1, 5, 0.3)

pbinom(q=2, size=5, prob=0.3)

1 - pnorm(q = 23, mean = 20, sd = 2)

pnorm(q = 20, mean = 20, sd = 2)

pnorm(q = 23, mean = 20, sd = 2) - pnorm(q = 16, mean = 20, sd = 2)

1 - pnorm(q = 0.75, mean = 0.67, sd = 0.01487)

pnorm(q = 0.50, mean = 0.67, sd = 0.01487)

qnorm(.975, 120.1, 20)

```

# Quiz 3 Workspace

```{r}
Quiz3Data <- read.csv("SAT_Scores_100.csv")
Quizx <- Quiz3Data$SampleData

z.test(x=Quizx, sigma.x=116, mu=525, alternative = "greater", conf.level = 0.95)
sd(Quizx)

Quiz3Data1 <- read.csv("SAT_Scores_20.csv")
Quizy <- Quiz3Data1$SampleData

ad.test(Quizy)
qqPlot(Quizy)

t.test(x=Quizy, mu=530, alternative = "greater", conf.level = 0.97)
sd(Quizy)

tsum.test(mean.x=575.85,s.x=123.7903,n.x=20,mu=530,alternative = 'greater',conf.level = 0.97)

```
